# -*- coding: utf-8 -*-

import os
import requests
import xml.etree.ElementTree as ET
import hashlib
import time
from datetime import datetime, timezone
from email.utils import parsedate_to_datetime
import json
import google.generativeai as genai
from firebase_admin import firestore, initialize_app
from firebase_functions import https_fn, options

# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹ã‚ˆ
import config

# Firebaseã¨Geminiã‚’åˆæœŸåŒ–ã™ã‚‹ã‚ˆ
initialize_app()

# â˜…è¶…å¤§äº‹â˜… Geminiã®APIã‚­ãƒ¼ã‚’å®‰å…¨ãªå ´æ‰€ã‹ã‚‰èª­ã¿è¾¼ã‚€è¨­å®š
options.set_global_options(secrets=["GEMINI_API_KEY"])

# ã“ã®é–¢æ•°ãŒURLã§å‘¼ã°ã‚ŒãŸã‚‰å®Ÿè¡Œã•ã‚Œã‚‹ï¼
@https_fn.on_request(timeout_sec=540) # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’9åˆ†ã«å»¶é•·ï¼
def fetch_and_summarize_articles(req: https_fn.Request) -> https_fn.Response:
    """
    Google Newsã®RSSã‹ã‚‰ã‚³ãƒ¼ãƒ’ãƒ¼é–¢é€£ã®è¨˜äº‹ã‚’å–å¾—ã—ã¦ã€
    Geminiã§è¦ç´„ã—ã¦Firestoreã«ä¿å­˜ã™ã‚‹HTTPé–¢æ•°ã ã‚ˆã‚“ï¼
    Cloud Schedulerã‹ã‚‰ã®å‘¼ã³å‡ºã—ã‚’æƒ³å®šã—ã¦ã„ã‚‹ã‚ˆã€‚
    """
    try:
        genai.configure(api_key=os.environ.get("GEMINI_API_KEY"))
        db = firestore.client()
        model = genai.GenerativeModel('gemini-1.5-flash')

        total_articles_saved = 0
        # ãƒãƒƒãƒå‡¦ç†ç”¨ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æº–å‚™
        batch = db.batch()
        # å®Ÿè¡Œä¸­ã®ã‚¿ã‚¤ãƒˆãƒ«é‡è¤‡ã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹ãŸã‚ã®ã‚»ãƒƒãƒˆ
        processed_title_prefixes = set()
        TITLE_PREFIX_LENGTH = 30 # ã‚¿ã‚¤ãƒˆãƒ«ã®å…ˆé ­ä½•æ–‡å­—ã§é‡è¤‡åˆ¤å®šã™ã‚‹ã‹
        # ä»Šå›ã®åé›†å‡¦ç†ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã™ã‚‹ãŸã‚ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯IDï¼ˆå®Ÿè¡Œé–‹å§‹æ™‚ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ï¼‰
        batch_id = int(time.time())

        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }

        # å„ãƒ•ã‚£ãƒ¼ãƒ‰ã‚’ãƒ«ãƒ¼ãƒ—ã—ã¦å‡¦ç†
        for feed in config.FEEDS:
            print(f"ã‚«ãƒ†ã‚´ãƒª '{feed['country_name']}' ã®è¨˜äº‹ã‚’åé›†ä¸­...")
            try:
                response = requests.get(feed['url'], headers=headers, timeout=15) # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’è¨­å®š
                response.raise_for_status() # HTTPã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Œã°ä¾‹å¤–ã‚’ç™ºç”Ÿ
                root = ET.fromstring(response.content)
            except requests.exceptions.RequestException as e:
                print(f"  [ã‚¨ãƒ©ãƒ¼] '{feed['country_name']}' ã®RSSãƒ•ã‚£ãƒ¼ãƒ‰å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                continue # ã“ã®å›½ã®å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦æ¬¡ã«é€²ã‚€
            except ET.ParseError as e:
                print(f"  [ã‚¨ãƒ©ãƒ¼] '{feed['country_name']}' ã®XMLãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                continue # ã“ã®å›½ã®å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦æ¬¡ã«é€²ã‚€

            # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å–å¾—ä»¶æ•°ã‚’èª­ã¿è¾¼ã‚€ã‚ˆ
            num_articles_to_fetch = feed['articles_to_fetch']
            # è¨˜äº‹ã®å‡¦ç†é †ã‚’è¨˜éŒ²ã™ã‚‹ãŸã‚ã®ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ï¼ˆå›½ã”ã¨ã«ãƒªã‚»ãƒƒãƒˆï¼‰
            sequence_counter = 0

            # å„ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰æœ€æ–°ã®è¨˜äº‹ã‚’å‡¦ç†ã™ã‚‹ã‚ˆ
            for item in root.findall('.//item')[:num_articles_to_fetch]:
                title = item.find('title').text
                link = item.find('link').text
                pub_date_str = item.find('pubDate').text

                # --- â–¼â–¼â–¼ ã‚¿ã‚¤ãƒˆãƒ«ã«ã‚ˆã‚‹é‡è¤‡æ’é™¤ â–¼â–¼â–¼ ---
                title_prefix = title[:TITLE_PREFIX_LENGTH]
                if title_prefix in processed_title_prefixes:
                    print(f"  [ã‚¹ã‚­ãƒƒãƒ—] ã‚¿ã‚¤ãƒˆãƒ«ãŒé¡ä¼¼ã—ãŸè¨˜äº‹ã‚’æ—¢ã«å‡¦ç†æ¸ˆã¿ã§ã™: {title}")
                    continue # ã“ã®è¨˜äº‹ã®å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—
                # --- ã“ã“ã¾ã§ ---

                # --- â–¼â–¼â–¼ é‡è¤‡æ’é™¤ã®ãŸã‚ã®ä¿®æ­£ â–¼â–¼â–¼ ---
                # linkã®ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆå…ˆã®æœ€çµ‚URLã‚’å–å¾—ã—ã¦ã€ãã‚Œã‚’è¨˜äº‹ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªIDã¨ã™ã‚‹
                try:
                    # HEADãƒªã‚¯ã‚¨ã‚¹ãƒˆã§åŠ¹ç‡çš„ã«æœ€çµ‚URLã‚’å–å¾—ï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚‚è¨­å®šï¼‰
                    head_response = requests.head(link, headers=headers, allow_redirects=True, timeout=10)
                    head_response.raise_for_status()
                    final_url = head_response.url
                except requests.exceptions.RequestException as e:
                    print(f"  [è­¦å‘Š] æœ€çµ‚URLã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}ã€‚å…ƒã®ãƒªãƒ³ã‚¯ã‚’IDã¨ã—ã¦ä½¿ç”¨ã—ã¾ã™ã€‚ Link: {link}")
                    final_url = link # å¤±æ•—ã—ãŸå ´åˆã¯å…ƒã®ãƒªãƒ³ã‚¯ã‚’ãã®ã¾ã¾ä½¿ã†

                # RSSã®å…¬é–‹æ—¥æ™‚ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦datetimeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›ã™ã‚‹ã‚ˆ
                try:
                    pub_date = parsedate_to_datetime(pub_date_str)
                except (TypeError, ValueError):
                    pub_date = datetime.now(timezone.utc) # ãƒ‘ãƒ¼ã‚¹å¤±æ•—ã—ãŸã‚‰ä»Šã®æ™‚é–“

                # æœ€çµ‚URLã‚’ãƒãƒƒã‚·ãƒ¥åŒ–ã—ã¦Firestoreã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆIDã«ã™ã‚‹ï¼ˆå¼·åŠ›ãªé‡è¤‡é˜²æ­¢ï¼ï¼‰
                doc_id = hashlib.sha256(final_url.encode('utf-8')).hexdigest()
                article_ref = db.collection('articles').document(doc_id)

                # --- å¤ã„ãƒ‡ãƒ¼ã‚¿ã®ãŠæƒé™¤æ©Ÿèƒ½ ---
                # ã‚‚ã—åŒã˜ãƒªãƒ³ã‚¯ã§ã€country_codeãŒ2æ–‡å­—ã˜ã‚ƒãªã„å¤ã„ãƒ‡ãƒ¼ã‚¿ãŒã‚ã£ãŸã‚‰å‰Šé™¤ã™ã‚‹
                old_docs_query = db.collection('articles').where('link', '==', link)
                for old_doc in old_docs_query.stream():
                    old_data = old_doc.to_dict()
                    if len(old_data.get('country_code', '')) != 2:
                        print(f"  [ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—] å¤ã„å½¢å¼ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‰Šé™¤ã—ã¾ã™: {old_doc.id} (country_code: {old_data.get('country_code')})")
                        batch.delete(old_doc.reference) # ãƒãƒƒãƒã«å‰Šé™¤æ“ä½œã‚’è¿½åŠ 
                # --- ã“ã“ã¾ã§ ---

                try:
                    print(f"  å‡¦ç†ä¸­ã®è¨˜äº‹: {title}")

                    # ã“ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’å‡¦ç†æ¸ˆã¿ã¨ã—ã¦ã‚»ãƒƒãƒˆã«è¿½åŠ 
                    processed_title_prefixes.add(title_prefix)

                    # Geminiãã‚“ã«è¦ç´„ã‚’ãŠé¡˜ã„ã™ã‚‹ï¼
                    prompt_text = feed['prompt'].format(title=title, link=link)
                    summary_response = model.generate_content(prompt_text)

                    try:
                        # Geminiã‹ã‚‰ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¯ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã§è¿”ã£ã¦ãã‚‹ã“ã¨ãŒã‚ã‚‹ã®ã§ã€```json ... ``` ã‚’å–ã‚Šé™¤ã
                        cleaned_response = summary_response.text.strip().replace("```json", "").replace("```", "")
                        result = json.loads(cleaned_response)
                        processed_title = result.get("title", title)
                        summary = result.get("summary", "è¦ç´„ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                        tags = result.get("tags", []) # GeminiãŒç”Ÿæˆã—ãŸã‚¿ã‚°ã‚’å–å¾—ã™ã‚‹ã‚ˆ
                    except (json.JSONDecodeError, AttributeError) as e:
                        print(f"    [è­¦å‘Š] JSONã®ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—: {e}. ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {summary_response.text}")
                        processed_title = f"{title} (å‡¦ç†å¤±æ•—)"
                        summary = "è¨˜äº‹ã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸã€‚å…ƒã®è¨˜äº‹ã‚’ã”ç¢ºèªãã ã•ã„ã€‚"
                        tags = []

                    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
                    article_data = {
                        'title': processed_title,
                        'link': link,
                        'original_link': final_url, # æœ€çµ‚çš„ãªURLã‚‚ä¿å­˜ã—ã¦ãŠã
                        'summary': summary,
                        'tags': tags, # ç”Ÿæˆã—ãŸã‚¿ã‚°ã‚’ä¿å­˜
                        'published_at': pub_date,
                        'region': feed['region'],
                        'region_name': config.REGIONS[feed['region']],
                        'country_code': feed['country_code'],
                        'country_name': feed['country_name'],
                        'created_at': firestore.SERVER_TIMESTAMP,
                        'batch_id': batch_id, # åé›†ãƒãƒƒãƒID
                        'sequence_id': sequence_counter # ãƒãƒƒãƒå†…ã§ã®å‡¦ç†é †
                    }
                    batch.set(article_ref, article_data, merge=True) # ãƒãƒƒãƒã«æ›¸ãè¾¼ã¿æ“ä½œã‚’è¿½åŠ 
                    total_articles_saved += 1

                except Exception as e:
                    print(f"  [ã‚¨ãƒ©ãƒ¼] è¨˜äº‹ '{title}' ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                    continue # ã“ã®è¨˜äº‹ã®å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦æ¬¡ã«é€²ã‚€
                finally:
                    # æˆåŠŸãƒ»å¤±æ•—ã«é–¢ã‚ã‚‰ãšã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’å¢—ã‚„ã™
                    sequence_counter += 1
            
            # ã‚µãƒ¼ãƒãƒ¼ã«è² è·ã‚’ã‹ã‘ãªã„ã‚ˆã†ã«ã€ã¡ã‚‡ã£ã¨å¾…ã¤
            print("  æ¬¡ã®å›½ã«è¡Œãå‰ã«ã¡ã‚‡ã£ã¨ä¼‘æ†©... â˜•")
            time.sleep(1)

        # ãƒ«ãƒ¼ãƒ—ãŒçµ‚ã‚ã£ãŸã‚‰ã€ãƒãƒƒãƒå‡¦ç†ã‚’ã¾ã¨ã‚ã¦å®Ÿè¡Œï¼
        if total_articles_saved > 0:
            print(f"åˆè¨ˆ {total_articles_saved} ä»¶ã®å¤‰æ›´ã‚’Firestoreã«ä¸€æ‹¬ã‚³ãƒŸãƒƒãƒˆã—ã¾ã™ã€‚")
            batch.commit()
        return https_fn.Response(f"ã‚¤ã‚±ã¦ã‚‹è¨˜äº‹ã‚’åˆè¨ˆ {total_articles_saved} ä»¶GETã—ã¦ä¿å­˜ã—ã¨ã„ãŸã‚ˆï¼âœ¨")

    except Exception as e:
        print(f"ã¾ã˜ã”ã‚ã‚“ã€ã‚¨ãƒ©ãƒ¼ã§ãŸ: {e}")
        return https_fn.Response("å†…éƒ¨ã§ã‚¨ãƒ©ãƒ¼ã§ãŸã‚â€¦ã”ã‚ã‚“ã¦ğŸ™", status=500)